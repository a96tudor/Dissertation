\begin{document}
	\chapter{Conclusion}
		In this dissertation, I have outlined the work done in designing, implementing and evaluating a machine-learning based extension for the CADETS UI with the purpose of filtering graph-structured OS-level provenance data. It classifies the nodes either into nodes that are of interest or nodes that are not of interest, from a cybersecurity perspective. As expected, by analysing several datasets, I observed that these two classes are highly imbalanced (i.e. there are more nodes that don't represent a potential threat than nodes that do). This imbalance in the data labels and the fact that there are multiple node types that had to be represented added a degree of complexity to the problem at hand. Through this dissertation, I have shown how these difficulties were overcome using suitable pre-processing techniques and machine learning models. 
		\\ \\
		The project requirements were all successfully achieved and a set of extensions were implemented. The evaluation of the models analyses both their performance (using a number of standard metrics) and their applicability to the problem at hand. 
		
	\section{Lessons learnt} 
		This project gave me the opportunity to explore several machine learning techniques, both parametric and non-parametric, and how they can be applied to real-world data. The Neo4J-stored graph cannot be passed directly to the machine learning models. For this reason, I also explored a few data processing techniques in order to come up with a feature vector representation for every node. Finally, I explored different API architectures that would allow the machine learning models to run as an independent entity, for the CADETS UI to make requests to.
		\\ \\
		Because the machine learning models represent the core module of this project and each model in part underwent continuous fine-tuning, the iterative and incremental development model has proven to be appropriate choice for the project at hand. Using Python as the main programming language was also appropriate, having support for data processing and machine learning development through libraries such as Numpy and Keras. Moreover, it also provides support for handling incoming network requests through the Flask library, essential in developing the REST API that wraps around the machine learning models.
		\\ \\
		If I were to do the project again, I would allow even more time to exploring different machine learning techniques, so that I could implement models that use even more of the relational nature of the graph data. On top of that, I would have allowed more time to fine-tuning the neural networks, given the fact that a performant machine learning model does not require a predefined set of steps, but it is rather a matter of trial and error.
	\section{Further work}
		Working on this project gave me the opportunity to explore areas of Computer Science that were intriguing, but still very little known to me. Personally, I find that this was an extraordinary learning experience and I consider the project a success. However, there are many possible extensions that can be implemented in order to make it even more successful, including:
		\begin{enumerate}
			\item \textit{Exploring more complex neural networks} - Machine learning applied on graphs is a current research trend, with more and more architectures being designed specifically for graph-structured data. Implementing one of these NN architectures would allow me to make more use of the relational nature of the data than I currently do. Two of the models that I would like to implement are Graph Convolutional Networks \cite{kipf2017semi} and Graph Attention Networks \cite{2017arXiv171010903V}.
			
			\item \textit{Solving the Neo4J access bottleneck} - Overcome the low time performance of the library that facilitates the Neo4J connection. One potential solution would be to replicate the database over multiple instances and perform the feature extraction in parallel. 
				
			\item \textit{Implementing machine learning models that can adapt to user input} - In the final stage, the machine learning models filtering the graph data should accept and adapt from user input, rather than just using a set of predefined rules. The logical next step would be to extend the models such as they can support this, while preserving their performance.
	\end{enumerate}
	
\end{document}