\begin{document}
	\chapter{Implementation}
	This chapter describes the describes how the requirements described in the previous chapter have been accomplished. 
	\section{Overall structure of the project} \label{Section: impl/overview}
	The main objective I had while implementing the project was to be able to have a completely independent tool that is can communicate with the CADETS client and classify nodes successfully. In order to achieve this, I divided the overall project into three smaller sub-modules:
	
	\begin{enumerate}
		\item \label{impl/overview/enum/1} The \textbf{Neo4J interface}, which handles the interaction between my tool and the Neo4J database that stores the raw graph data with the end purpose of extracting the nodes' feature vectors. This is described in detail in Section \ref{Section: impl/neo4j}.
		\item The \textbf{machine learning models}, which use the feature vectors extracted as part of the \ref{impl/overview/enum/1}$^{\text{st}}$ module in order to classify the nodes into \textit{SHOW} or \textit{HIDE}. The exact details of how they were implemented in Section \ref{Section: impl/ml}.
		\item The \textbf{REST API}, which wraps around the previous two modules and handles requests received by the tool. This is described in detail in Section \ref{Section: impl/REST}.
	\end{enumerate}
	Figure \ref{Fig: impl/pipeline} shows a schema of how the 3 modules will work together as a part of a request processing pipeline. 
	\\ \\
	In the following sections, I will describe the modules listed above in a bottom-up approach -- from the Neo4J interaction to the REST API. 
	\begin{figure}[H]
		\centering
		\includegraphics[width=.95\textwidth]{graphics/overall-schema}	
		\caption[Processing pipeline]{Overview of the project's processing pipeline.}
		\label{Fig: impl/pipeline}
	\end{figure}
	\section{Neo4J interaction} \label{Section: impl/neo4j}
	This section describes how the project I implemented interacts with the Neo4J database and how the features for every node are extracted. 
	\subsection{Database driver} \label{Section: impl/neo4j/driver}
	The biggest challenge when designing the database driver was the choice of the library I would use to run the actual queries. There are a number of Python libraries available, out of which I took two into consideration: \textbf{py2neo}\footnote{\textbf{\url{http://py2neo.org/v3/}}} and \textbf{neo4j-driver}\footnote{\textbf{\url{https://github.com/neo4j/neo4j-python-driver}}}. In order to decide which one I will use, I timed the running of two queries(\textit{match (n) return n} and \textit{match(n) return n limit 1} ) and the overall feature extraction for one node on a database of $631, 357 \text{ nodes}$ for both libraries. The resulting times are shown in Table \ref{Table: impl/neo4j-driver-timings}:
	\begin{longtable}{|p{.15\textwidth}|p{.30\textwidth}p{.25\textwidth}p{.25\textwidth}|}
		\textbf{library} & \textbf{\textit{match(n) return n}} & \textbf{\textit{match(n) return n limit 1}} & \textbf{feature extraction} \\
		\hline
		\textit{py2neo} & $337.477\text{s } (\approx5.5 \text{ minutes})$ & $13\text{ms}$ & TODO \\ 
		\textit{neo4j-driver} & $97.288\text{s }(\approx1.5 \text{ minutes})$ & $28\text{ms}$ & $68.78\text{s}$  \\
		\hline
		\caption[Neo4J libraries timings]{\centering Table showing the timings for the two libraries considered}
		\label{Table: impl/neo4j-driver-timings}
	\end{longtable}
	The main purpose of the database driver is to support feature extraction(detailed in Section \ref{Section: impl/neo4j/features}). Therefore, given the times in Table \ref{Table: impl/neo4j-driver-timings}, I decided to use \textbf{neo4j-driver}. On top of this library, I wrote a wrapper class, \textbf{DatabaseDriver}. 
	\subsection{Feature extractor} \label{Section: impl/neo4j/features}
	The feature extractor uses the DatabaseDriver described in the previous section in order to build the feature vectors for a list of nodes, just as described in Table \ref{Table: prep/features}. Therefore, the two classes will be in an association relationship (i.e. the FeatureExtractor has one instance of DatabaseDriver), as displayed in Figure \ref{Fig: impl/neo4j-driver-uml}.
	\\ \\
	Considering the fact that the machine learning models require purely real feature vectors to work, I decided to use \textbf{one-hot-encoding} for the categorical features. In other words, for every such feature, I generated one extra boolean column for each category. Only one of these columns can take the value 1 for each sample. Using this encoding led to an increase in the length of the feature vectors, from 13 to 23 variables. 
	\\ \\
	On top of extracting the feature matrix, this module also has support for generating the adjacency matrix of the nodes from the list provided. This is required for models such as the Graph Attention Networks (Section \ref{Section: impl/ml/gat}).
	\begin{figure}[H]
		\centering
		\includegraphics[width=.5\textwidth]{graphics/umls/uml-neo4j-driver}
		\caption[FeatureExtractor UML class diagram]{\centering UML class diagram showing the interaction between the feature extractor and the database driver.}
		\label{Fig: impl/neo4j-driver-uml}
	\end{figure}
	\section{Machine learning models} \label{Section: impl/ml}
	With the first module being implemented, I started to implement different machine learning models that I would use to classify the nodes. 
	\subsection{Training set} \label{Section: impl/ml/training-set}
	One of the key requirements for a well-behaved machine learning model is to have a comprehensive training set. Keeping this in mind, I used the ground-truths listed in Section \ref{Section: prep/data/ground-truths} with the aim of extracting examples of nodes from both classes (i.e. \textit{SHOW} and \textit{HIDE}) from a database of $6,007$ nodes, out of which $5,498$ are of interest (i.e. either \textit{File}, \textit{Process} or \textit{Socket}). For all these selected nodes, I used the feature extractor in order to build a labelled training set $\mathbf{s}=\{ (\mathbf{x}_1, \mathbf{y_1}), \dots, (\mathbf{x}_n, \mathbf{y_n}) \}$ that will be used by all the models in the training phase. As expected, there is a significant imbalance in the training data, with $2,382$ nodes ($43.33\%$) being labelled as \textit{SHOW} and $3,115$ ($56.67\%$) being labelled as \textit{HIDE}. This is a factor that I took into consideration both when designing and evaluating the models.
	\\ \\
	Moreover, using the same training set for all the models implemented is one of the key factors that ensure the correctness of the models' comparative evaluation. 
	\subsection{Baseline model} \label{Section: impl/ml/baseline}
	The baseline model 
	\subsection{Graph Attention Network} \label{Section: impl/ml/gat}
	\begin{figure}[H]
		\centering
		\includegraphics[width=.7\textwidth]{graphics/nns/gat}	
		\caption[Attention mechanism]{The attention mechanism computing the attention coefficients \\ $\alpha_{i,j}=\text{softmax}_j(a(\mathbf{Wh}_i, \mathbf{Wh}_j))$, where $a$ is the Leaky ReLU (LReLU) activation function, parametrized by a weight vector $\mathbf{a}\in\mathbb{R}^{2F'}$, namely: \\  $a(\mathbf{Wh}_i, \mathbf{Wh}_j)=\text{LReLU}(\mathbf{a}^T[\mathbf{Wh}_i\mid\mid\mathbf{Wh}_j])$}.
		\label{Fig: impl/attn-mechanism}
	\end{figure}
	\subsection{Probabilistic Neural Networks} \label{Section: impl/ml/pnn}
	The implementation of Probabilistic Neural Networks (PNNs) consisted of two steps: PNN training and classification. 
	\begin{algorithm}[H]
		\caption{PNN training}
		\begin{algorithmic}
			\Procedure{train\_PNN}{}
				\State $j \gets 0$
				\State $n \gets \text{number of patterns}$ 
				\Do
					\State $j \gets j + 1$
					\State $x_{jk} \gets \frac{x_{jk}}{\sqrt{\sum_{i=1}^{d}x_{ij}^2}}$ \Comment{\textbf{normalization}}
					\State $w_{jk} \gets x_{jk}$ \Comment{\textbf{setting weight values}}
					\If{$\mathbf{x} \in \omega_i$}
						\State $a_ic \gets 1$
					\EndIf
				\doWhile{$j \neq n$}
			\EndProcedure
		\end{algorithmic}
	\end{algorithm}
	\begin{algorithm}
	\caption{PNN classification}
	\begin{algorithmic}[H]
		\Procedure{classify\_PNN}{$\mathbf{x}$}
		\State $k \gets 0$
		\State $n \gets \text{number of patterns}$ 
			\Do
				\State $k \gets k + 1$
				\State $z_k \gets \mathbf{w_k}^T\mathbf{x}$
				\If{$a_{kc} = 1$}
					\State $g_c \gets g_c + \exp(\frac{z_k - 1}{\sigma^2})$
				\EndIf
			\doWhile{$k \neq n$} 
		\State $class \gets \argmax_i g_i(\mathbf{x})$ \\
		\Return{class}
		\EndProcedure
	\end{algorithmic}
\end{algorithm}
	\section{REST API} \label{Section: impl/REST}
	This section describes how the REST API layer that eases the application's interaction with the CADETS user interface was implemented.
	\subsection{Actual REST API} \label{Section: impl/REST/actual}
	The main entry point to the REST API receives a POST HTTP request from the client, containing a JSON file with a list of nodes to classify. Each node in the list will be represented by a (\textit{uuid}, \textit{timestamp}) pair, which allows the tool to uniquely identify it in the Neo4J database. The API then initiates a 'job' that starts classifying the nodes in background and replies with a JSON containing its ID.
	\\ \\
	Using this job ID, the client can then query the API using an HTTP GET request and the API will reply with a different JSON containing two fields: \textit{"results"} and \textit{"status"}. The \textit{"results"} field contains the list of nodes that have been classified so far as part of the job in question. The \textit{"status"} field can take one of three values, depending on what the status of the job is: \textit{WAITING} means that it is idle, \textit{RUNNING} means that the job is still classifying nodes and therefore the results returned are partial (i.e. only for a subset of the nodes) and \textit{DONE} represents the fact that the job is finished and the returned classification results are for the entire set of nodes queried initially. 
	\\ \\
	I decided to implement this 2-step mechanism due to the fact that node classification can take a long time, especially when working with large databases. This way, the client sends one request and then can query the API at any time for the job status and partial or final classification results. Figure \ref{Fig: impl/REST/API-integrate} shows how these jobs work in relation with the other modules.
	
	Another key factor that I took into consideration is how the API will treat different types of nodes, given the fact that the machine learning models only apply to \textit{File}, \textit{Socket} and \textit{Process} nodes. Table \ref{Table: impl/REST/API-strategy} shows the strategies adopted by the API for different types of nodes.
	\begin{longtable}{|p{.15\textwidth}|p{.85\textwidth}|}
		\textbf{Node type} & \textbf{API strategy} \\
		\hline
		\textit{File} & \multirow{3}{*}{Return the classification result for the node.} \\
		\textit{Socket} & \\
		\textit{Process} & \\
		\hline
		\textit{Machine} & Only represents $0.00178\%$ of the total number of nodes, so consider classified as \textit{SHOW} by default. \\
		\hline
		\textit{Meta} & \multirow{2}{*}{Return the classification result for the \textit{Process} node that it is connected to.} \\
		\textit{Pipe} & \\
		\hline
		\caption{API strategy for different type of nodes}
		\label{Table: impl/REST/API-strategy}
 	\end{longtable}
 
	\subsection{Caching mechanism} \label{Section: impl/REST/caching}
	Due to the stateless nature of REST APIs, caching is a desirable feature in order to avoid a high load on the application. Moreover, an efficient caching mechanism is essential to support the 2-step format of the API described in Section \ref{Section: impl/REST/actual}. 
	\\ \\
	In order to handle caching, I am using a PostgreSQL database, for its object-relational format. Unlike other SQL dialects (such as MySQL), it is highly customizable, providing stored procedures in more than a dozen programming languages, including Java, Perl and Python. 
	\\ \\
	The actual database structure is made of two tables: \textit{Jobs} (which stores all the jobs processed by the server and their status) and \textit{Nodes} (which stores the cached results for the nodes that have been processed over time). The full relational schema is shown in Figure \ref{Fig: impl/REST/cache/relational}.
	\begin{figure}[H]
		\centering
		\includegraphics[width=.7\textwidth]{graphics/cache-schema}
		\caption[Cache schema]{Figure showing the relational schema used by the caching mechanism}
		\label{Fig: impl/REST/cache/relational}
	\end{figure}
	By default, every cache entry is invalidated 24 hours after the job that the node is associated with is finished. On top of this, the API provides an entry point for forcibly clearing the cache. 
	
	\section{Modularity \& Scalability} \label{Section: impl/modularity&scalability}
	During the implementation of the API, I had two goals in mind: modularity and scalability. In order to achieve this, every section makes use of the object-oriented paradigm (as shown in Figure \ref{Fig: impl/REST/API-integrate}). This allows anyone who wants to extend the tool to do so with ease, by simply extending one class and specifying this when starting the API.  
	\begin{figure}[H]
		\centering
		\includegraphics[width=.9\textwidth]{graphics/umls/full-system-uml}
		\caption[General UML diagram]{\centering UML diagram showing the integration of API's jobs with the previous two modules(i.e. feature extractor and machine learning models).}
		\label{Fig: impl/REST/API-integrate}
	\end{figure}
	The \textbf{feature extractor} can connect to any Neo4J database that has the structure described in Section \ref{Section: prep/datastructure} and extract feature vectors for the nodes. 
	\\ \\
	Anyone can add a new machine learning model to the API, by simply extending the abstract class \textit{models.Model}. The new model can be used by the API by simply specifying it as a parameter.  
	\\ \\
	The REST-like architecture of the API allows for the server-side model to scale horizontally, by balancing the load between multiple instances of the server. The cache can then be either shared by all the instances, or have one cache for each instance. In both cases, though, the cache database can be scaled vertically by running it on a more powerful machine. 
	
	\section{Summary} \label{Section: impl/summary}
\end{document}